[
    {
        "id": "tech-unemploy-women",
        "title": "Inégalités de genre et technologie : ce que la data révèle",
        "excerpt": "Cet article étudie l’impact du progrès technologique sur le chômage féminin en Europe à partir de données régionales (2012–2021) et d’une approche économétrique spatiale. Les résultats montrent que l’augmentation de l’emploi technologique réduit le chômage féminin, localement et dans les régions voisines. En revanche, la montée des travailleurs hautement qualifiés en sciences et technologies peut accentuer les inégalités lorsque l’accès des femmes aux filières STEM reste limité. Cette analyse souligne que la technologie n’est inclusive que si elle s’accompagne de politiques éducatives et territoriales adaptées, et illustre le rôle de la data pour éclairer des enjeux sociaux complexes.",
        "date": "2026-01-09T13:59",
        "lang": "fr",
        "cover": "assets/img/blog/blog1.png",
        "tags": ["Unemployment", "Spatial Econometrics", "Women", "Technology"],
        "content": "## Introduction\n\nDans un contexte de transformation rapide des économies européennes, le progrès technologique est souvent présenté comme un moteur de croissance et d’opportunités. Automatisation, numérisation et innovation redessinent profondément le marché du travail.\nMais ces transformations profitent-elles réellement à tout le monde de la même manière ?\n\nCe travail s’intéresse à une question centrale : comment le développement technologique influence-t-il le chômage féminin en Europe, et surtout, comment ces effets varient-ils selon les territoires.\n\nL’objectif de cette étude est double.\nD’une part, quantifier l’impact de la technologie sur l’emploi féminin.\nD’autre part, montrer que ces effets ne sont pas isolés : les régions interagissent entre elles, et ce qui se passe dans un territoire peut influencer ses voisins.\n\nC’est précisément là que la data et l’économétrie spatiale deviennent des outils essentiels pour comprendre des phénomènes complexes du monde réel.\n\n![illus1](assets/img/blog/blog1_img0.png)\n\n## Les données : quand l’Europe devient un terrain d’analyse\n\nL’analyse repose sur des données Eurostat couvrant la période 2012–2021, avec un panel de 73 régions européennes réparties entre la France, l’Espagne, l’Italie, les Pays-Bas et la Belgique.\n\nCes données permettent de suivre l’évolution du chômage féminin dans le temps, tout en comparant des régions aux profils économiques très différents.\n\nLes principales variables mobilisées sont :\n- le taux de chômage féminin, variable centrale de l’analyse ;\n- la part de l’emploi technologique, indicateur de diffusion de l’innovation ;\n- la proportion de travailleurs hautement qualifiés en sciences et technologies (HRST) ;\n- le PIB régional ;\n- le niveau d’éducation supérieure ;\n- la densité de population, proxy de l’urbanisation.\n\nCes données forment un panel spatio-temporel, particulièrement adapté à une analyse fine des dynamiques territoriales.\n\n![illus2](assets/img/blog/blog1_img1.png)\n\n## Pourquoi une approche spatiale change tout?\n\nAnalyser chaque région indépendamment serait une erreur.\nLes régions ne sont pas isolées : mobilité du travail, diffusion des compétences, attractivité économique… tout circule.\n\nPar exemple :\n\nSi le chômage diminue dans une région innovante, cela peut-il bénéficier aux régions voisines ?\n\nPour répondre à cette question, j’ai utilisé un modèle économétrique spatial de type SAR (Spatial Autoregressive) avec effets fixes.\n\nCe type de modèle permet de distinguer :\n- les effets directs : impact local du progrès technologique ;\n- les effets indirects (spillovers) : impact sur les régions voisines.\n\nC’est une manière concrète de traduire mathématiquement l’idée que l’économie est interconnectée, et que les politiques locales peuvent avoir des effets régionaux plus larges.\n\n![illus3](assets/img/blog/blog1_img2.png)\n\n## Résultats clés : ce que disent les chiffres\n\nLes résultats révèlent des effets contrastés mais très instructifs.\n\nUne augmentation de 1 % de l’emploi technologique est associée à :\n\n* une baisse de 0.52 point du chômage féminin localement ;\n* une baisse de 0.41 point dans les régions voisines.\n\nCela suggère que le progrès technologique est porteur d’externalités positives, au-delà des frontières régionales.\n\n**Le paradoxe des qualifications**\nÀ l’inverse, une hausse de la part de travailleurs hautement qualifiés en sciences et technologies (HRST) augmente le chômage féminin.\n\nCe résultat met en évidence un effet de concurrence :\nsi les femmes restent sous-représentées dans les filières STEM, l’élévation générale du niveau de qualification peut renforcer les exclusions existantes.\n\nEn revanche, l’éducation supérieure apparaît comme un levier majeur, réduisant significativement le chômage féminin.\n\n## Ce que cette étude nous apprend vraiment\n\nCe travail montre que le progrès technologique n’est pas automatiquement inclusif.\nIl peut créer des opportunités, mais aussi renforcer des inégalités existantes si les politiques d’accompagnement sont insuffisantes.\n\nLa data permet ici de dépasser les discours généraux et de mesurer précisément où, comment et pour qui les effets se produisent.\nPour les décideurs publics, cette analyse souligne la nécessité de politiques ciblées, notamment en faveur de la formation numérique et technologique des femmes.\n\nPour les entreprises et institutions, elle montre comment la data et l’économétrie appliquée peuvent éclairer des enjeux sociaux complexes.\n\nEnfin, pour le grand public, elle illustre une idée clé :\n\nla donnée n’est pas abstraite — elle permet de comprendre, d’anticiper et d’agir sur des problèmes réels du monde contemporain."
    },
    {
        "id": "house-price-pred",
        "title": "Predicting House Prices in the USA with Machine Learning",
        "excerpt": "This article explores how machine learning models can be used to predict house prices in the United States. Using structured housing data and a comparative modeling approach, the project highlights the importance of data preparation and feature engineering, showing how data-driven methods can help explain and anticipate real-world economic outcomes.",
        "date": "2026-01-10T08:16",
        "lang": "fr",
        "cover": "assets/img/blog/house.jpg",
        "tags": [
            "Machine Learning",
            "Data Science",
            "Regression",
            "Python"
        ],
        "content": "## Why Predicting House Prices Matters\n\nHousing prices play a central role in modern economies. They affect household wealth, access to property, investment decisions, and even geographic mobility. Accurately estimating house prices is therefore not only a technical challenge, but also an economic and social one.\n\nThis project investigates how **machine learning regression models** can be leveraged to predict house prices in the USA, and what these models reveal about the underlying structure of housing markets.\n\nThe goal is not only performance, but also **understanding what drives predictions** and how data quality shapes results.\n\n---\n\n## From Raw Data to Insight\n\nThe dataset contains information on housing characteristics such as:\n- average income of the area,\n- age of the house,\n- number of rooms and bedrooms,\n- local population,\n- and address-related information.\n\nThe target variable is the **house sale price**.\n\nA key part of the work consisted in **cleaning and structuring the data**, with particular attention paid to transforming raw variables into meaningful signals. One important insight from this project is that **how data is prepared often matters more than the choice of model itself**.\n\n---\n\n## A Data-Driven Modeling Approach\n\nSeveral regression models were tested and compared to evaluate their ability to capture price dynamics:\n\n- Linear Regression  \n- Bayesian Ridge Regression  \n- Random Forest  \n- Gradient Boosting  \n- K-Nearest Neighbors  \n- XGBoost  \n\nEach model offers a different trade-off between interpretability, flexibility, and predictive power. Rather than relying on a single algorithm, the project adopts a **comparative approach**, which is essential in applied data science.\n\n---\n\n## Model Performance and Results\n\nAfter careful preprocessing and feature engineering, the models were evaluated using standard regression metrics such as **Mean Squared Error (MSE)** and **R-squared ($R^2$)**.\n\n### Model comparison on validation data\n\n| Model | Test MSE | Test R² | Rank |\n|------|---------|--------|------|\n| **Gradient Boosting (XGBoost)** | **1.545e10** | **0.879** | **1** |\n| Bayesian Ridge | 1.663e10 | 0.870 | 2 |\n| Linear Regression | 1.664e10 | 0.870 | 3 |\n| Random Forest | 1.856e10 | 0.855 | 4 |\n| K-Nearest Neighbors | 1.861e10 | 0.855 | 5 |\n\nThe **XGBoost model** achieved the best overall performance, confirming the strength of ensemble methods on structured tabular data.\n\n---\n\n## Visualizing Predictions\n\nA useful way to assess model quality is to visually compare predicted prices to actual prices.\n\n<img src=\"assets/img/blog/blog2_img1.png\" alt=\"Actual vs Predicted house prices using XGBoost\" width=\"100%\">\n\nThe predictions closely follow the true values, with remaining errors mainly driven by extreme prices and local heterogeneity.\n\nThe distribution of predicted prices further highlights how well the model captures the overall structure of the market:\n\n<img src=\"assets/img/blog/blog2_img2.png\" alt=\"Distribution of predicted house prices\" width=\"100%\">\n\n---\n\n## Key Lessons Learned\n\nSeveral important lessons emerge from this project:\n\n- **Data preparation is critical**: cleaning, transforming, and exploiting available information (especially location-related features) led to significant performance gains.\n- **More complex models are not always better**, but tree-based boosting methods are particularly effective for heterogeneous economic data.\n- **Machine learning can support economic understanding**, not just prediction, by revealing which variables matter most.\n\nThis reinforces a central idea in applied data science:  \n> *Good models start with good data.*\n\n---\n\n## What This Project Demonstrates\n\nBeyond the technical results, this project illustrates how data science can be used to:\n- translate raw data into actionable insights,\n- support decision-making in economically meaningful contexts,\n- bridge the gap between statistical modeling and real-world problems.\n\nFor recruiters, institutions, and organizations, it highlights practical skills in:\n- data cleaning and feature engineering,\n- model comparison and evaluation,\n- and communicating results in a clear, structured way.\n\n---\n\n## Going Further\n\nFuture extensions could include:\n- integrating external geographic or economic indicators,\n- experimenting with alternative boosting frameworks,\n- or exploring neural-network-based approaches for regression.\n\nPredicting house prices is only one application — the broader takeaway is how **data-driven methods can help us better understand complex systems**, when used carefully and thoughtfully.\n\n---\n\n*Dataset source: USA Housing Dataset (GitHub)*"
    },
    {
        "id": "rec-sys",
        "title": "Système de Recommandation de Publications Scientifiques",
        "excerpt": "Dans un monde académique où des milliers de travaux scientifiques sont publiés chaque jour, il devient crucial d’aider les chercheurs à identifier rapidement les publications les plus pertinentes. Ce projet propose un système de recommandation de papiers scientifiques basé sur des techniques de traitement du langage naturel et de vectorisation de texte. L’objectif est de fournir des suggestions de lecture adaptées aux intérêts de l’utilisateur, tout en démontrant l’apport concret de la data science à un problème réel de recherche.",
        "date": "2026-01-10T08:34",
        "lang": "fr",
        "cover": "assets/img/blog/default.jpg",
        "tags": [
            "Machine Learning",
            "Data Science",
            "NLP",
            "Recommender Systems"
        ],
        "content": "## Pourquoi un système de recommandation de papiers scientifiques ?\n\nLa croissance rapide du nombre de publications rend la veille scientifique de plus en plus complexe. Les chercheurs sont confrontés à une abondance d’articles répartis entre de nombreuses revues et conférences, ce qui complique l’identification des travaux réellement utiles à leurs recherches.\n\nUn système de recommandation permet de structurer cette information et d’améliorer l’accès à la connaissance en proposant des articles en lien avec les thématiques d’intérêt d’un utilisateur.\n\n---\n\n## Principe général du système\n\nLe projet met en place un pipeline de recommandation basé sur l’analyse du contenu textuel des articles scientifiques. Les titres et résumés sont transformés en représentations numériques permettant de mesurer leur similarité sémantique.\n\nCette approche permet d’identifier des articles proches sur le fond, même lorsqu’ils n’utilisent pas exactement les mêmes termes.\n\n---\n\n## Données et préparation\n\nLe système s’appuie sur un corpus d’articles scientifiques comprenant notamment :\n- les titres,\n- les résumés,\n- des mots-clés et métadonnées associées.\n\nUne phase de nettoyage et de structuration est nécessaire afin d’obtenir des textes exploitables pour la modélisation. La qualité de cette étape conditionne directement la pertinence des recommandations produites.\n\n---\n\n## Représentation sémantique des textes\n\nPour comparer efficacement les articles, les textes sont encodés sous forme de vecteurs numériques à l’aide de méthodes de vectorisation. Le projet repose notamment sur l’utilisation de TF-IDF, qui permet de pondérer les termes en fonction de leur importance relative dans l’ensemble du corpus.\n\nCette représentation rend possible le calcul de similarités entre articles et constitue le cœur du moteur de recommandation.\n\n---\n\n## Interface et restitution des résultats\n\nLe système est exposé via une application web simple, permettant à l’utilisateur de saisir une requête ou de sélectionner un article de référence. Les publications jugées les plus proches sont alors affichées, facilitant la navigation et la découverte de nouveaux travaux scientifiques.\n\nL’objectif est de proposer un outil utilisable par des profils non techniques, tout en conservant une base méthodologique rigoureuse.\n\n---\n\n## Résultats et enseignements\n\nCe projet met en évidence plusieurs points essentiels :\n- la performance d’un système de recommandation dépend fortement de la qualité des données textuelles ;\n- les méthodes de vectorisation permettent de capturer des similarités thématiques pertinentes ;\n- des approches relativement simples peuvent déjà produire des résultats utiles dans un contexte académique.\n\nIl illustre également l’importance de l’analyse exploratoire pour ajuster les choix méthodologiques.\n\n---\n\n## Intérêt et perspectives\n\nAu-delà de l’aspect technique, ce projet montre comment les outils de data science et de traitement du langage naturel peuvent répondre à des problématiques concrètes liées à la diffusion du savoir.\n\nIl ouvre la voie à plusieurs extensions possibles, comme l’intégration de représentations sémantiques plus avancées, l’ajout de nouvelles sources de données ou l’adaptation du système à d’autres types de contenus.\n\n---\n\n## Ce que ce projet démontre\n\nCe travail met en avant :\n- une maîtrise des bases du traitement du langage naturel appliqué ;\n- la capacité à structurer un pipeline data de bout en bout ;\n- la transformation d’une approche analytique en outil exploitable ;\n- une réflexion orientée vers des usages réels dans le monde académique.\n\n---\n\n*Projet basé sur le repository GitHub « ResearchPapersRecommandationSystem ».*"
    }
]